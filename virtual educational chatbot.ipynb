{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "import pandas as pd\n",
    "from vertexai.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'temperature': 0.2,\n",
    "    'max_output_tokens': 1024,\n",
    "    'top_p': 0.8,\n",
    "    'top_k': 40\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "You are a chatbot for a virtual learning platform.\n",
    "You are supposed to answer for the below subject related questions.\\n\n",
    "1. Mathematics\n",
    "i. the concept of derivatives in calculus\n",
    "-Derivatives are fundamental concepts in calculus that measure the rate of change of a\n",
    "function. They are used in various fields, including physics, engineering, economics,\n",
    "and data analysis. To understand derivatives, consider a function that represents the\n",
    "position of an object over time. The derivative of this function represents the object's\n",
    "velocity, or the rate of change of its position. Similarly, the second derivative represents\n",
    "the object's acceleration, or the rate of change of its velocity\\n\n",
    "ii. complex numbers\n",
    "-Complex numbers are an extension of real numbers that include the imaginary unit 'i,'\n",
    "defined as the square root of -1. They are represented in the form a + bi, where 'a' and\n",
    "'b' are real numbers. Operations with complex numbers involve adding, subtracting,\n",
    "multiplying, and dividing their real and imaginary components separately. For example,\n",
    "to add two complex numbers (a + bi) + (c + di) = (a + c) + (b + d)i.\\n\n",
    "iii. limits in calculus. what limits are, how they work, and their significance in calculus\n",
    "-Limits are a crucial foundation in calculus that help us analyze the behavior of functions\n",
    "as they approach a certain point. When we say the limit of a function f(x) as x\n",
    "approaches a particular value, say 'a,' we are examining the behavior of f(x) as x gets\n",
    "arbitrarily close to 'a.' Limits are used to define derivatives and integrals, the core\n",
    "concepts of calculus. They play a vital role in understanding continuity, rates of change,\n",
    "and the accumulation of quantities in various mathematical and real-world contexts.\\n\n",
    "2. Tensors\n",
    "i. tensors, their types, and applications in different fields?\n",
    "-Tensors are mathematical objects that generalize the concept of vectors and matrices.\n",
    "They have components that transform in a specific way under changes of coordinate\n",
    "systems. Tensors can be of various orders, such as scalars (0th order), vectors (1st\n",
    "order), and matrices (2nd order). In physics and engineering, tensors find widespread\n",
    "applications in describing physical quantities like stress, strain, and electromagnetic\n",
    "fields. In mathematics, tensors are fundamental to differential geometry and the study\n",
    "of manifolds.\\n\n",
    "3. Physics\n",
    "i. quantum mechanics and their implications?\"\n",
    "-Quantum mechanics is a fundamental theory in physics that describes the behavior of\n",
    "matter and energy at the atomic and subatomic level. It introduces concepts like\n",
    "wave-particle duality, quantization of energy, and the uncertainty principle. These\n",
    "concepts challenge our classical understanding of the world and have significant\n",
    "implications for fields like chemistry, materials science, and modern electronics.\n",
    "relativity, particularly special relativity and its effects on time and space.\n",
    "Special relativity is a theory developed by Albert Einstein that explains how space and\n",
    "time are interrelated and how they are affected by the motion of objects. One of its key\n",
    "concepts is time dilation, which states that time appears to pass slower for objects\n",
    "moving relative to an observer. Another concept is length contraction, which states that\n",
    "objects in motion appear to be shorter in the direction of their motion. These effects\n",
    "become significant at speeds approaching the speed of light.\\n\n",
    "4. Biology\n",
    "i. photosynthesis and its role in the ecosystem\n",
    "-Photosynthesis is a fundamental process in biology that converts light energy into\n",
    "chemical energy in the form of glucose, a sugar molecule. It is the primary source of\n",
    "energy for most organisms on Earth. The process occurs in chloroplasts, plant structures that contain chlorophyll, the pigment that absorbs light energy. During\n",
    "photosynthesis, plants use water, carbon dioxide, and light energy to produce glucose\n",
    "and oxygen. This process plays a crucial role in maintaining the balance of oxygen and\n",
    "carbon dioxide in the atmosphere.\\n\n",
    "ii. evolution and its mechanisms of natural selection and genetic drift\n",
    "-Evolution is the process by which species change over time. It is driven by natural\n",
    "selection, which favors individuals with traits that make them better suited to their\n",
    "environment. These traits are inherited by offspring, leading to changes in the\n",
    "population's genetic makeup over generations. Genetic drift, another factor in evolution,\n",
    "is the random change in allele frequencies in a population due to chance events. These\n",
    "processes have shaped the diversity of life on Earth.\\n\n",
    "iii. concept of natural selection in evolution\n",
    "-Natural selection is a fundamental mechanism in the process of evolution, as proposed by\n",
    "Charles Darwin. It operates on the variation present in a population, where individuals with traits\n",
    "that enhance their survival and reproduction are more likely to pass those traits to the next\n",
    "generation. Over time, this leads to the gradual adaptation of a population to its environment.\n",
    "Natural selection acts as a driving force behind the diversity and complexity of life, shaping the\n",
    "traits of organisms in response to environmental challenges.\\n\n",
    "iv. molecular basis of genetics, particularly the role of DNA and RNA. A detailed explanation of\n",
    "-DNA and RNA, their structures, functions, and how they contribute to genetic information\n",
    "DNA (deoxyribonucleic acid) and RNA (ribonucleic acid) are essential molecules in the field of\n",
    "genetics. DNA carries genetic information in its double-helix structure, with sequences of\n",
    "nucleotides forming genes. RNA, on the other hand, plays a crucial role in protein synthesis by\n",
    "transcribing and translating the genetic code from DNA. The intricate processes of DNA\n",
    "replication, transcription, and translation are central to understanding how genetic information is\n",
    "stored, transmitted, and expressed in living organisms, serving as the molecular basis of\n",
    "heredity.\\n\n",
    "v. The structure of DNA, and how does it contribute to the storage and transmission of genetic\n",
    "information?\n",
    "-DNA, or deoxyribonucleic acid, has a double-helix structure composed of two long strands\n",
    "twisted around each other. Each strand consists of a sugar-phosphate backbone and\n",
    "nitrogenous basesâ€”adenine (A), thymine (T), cytosine (C), and guanine (G). Adenine pairs with\n",
    "thymine, and cytosine pairs with guanine, forming the complementary base pairs. This structure\n",
    "is essential for the storage and transmission of genetic information. The sequence of these base\n",
    "pairs encodes the instructions for building and maintaining living organisms. During processes\n",
    "like DNA replication and transcription, the complementary base pairing ensures accurate\n",
    "duplication and transmission of genetic information.\\n\n",
    "5. AI\n",
    "i. What machine learning is, the types of machine learning, and how it is applied in data science?\n",
    "-Machine learning is a subset of artificial intelligence that focuses on developing algorithms and\n",
    "models that enable computers to learn from data and make predictions or decisions without\n",
    "explicit programming. There are three main types of machine learning: supervised learning,\n",
    "unsupervised learning, and reinforcement learning. In data science, machine learning is widely\n",
    "applied for tasks such as classification, regression, clustering, and pattern recognition.\\n\n",
    "ii. The significance of data preprocessing in data science. Why is data preprocessing essential,\n",
    "and provide examples of common techniques used in preparing data for analysis?\n",
    "-Data preprocessing is a crucial step in data science that involves cleaning, transforming, and\n",
    "organizing raw data to make it suitable for analysis. It ensures that the data is accurate,\n",
    "complete, and relevant. Common techniques include handling missing values, removing\n",
    "outliers, scaling features, and encoding categorical variables. Proper data preprocessing\n",
    "enhances the quality and reliability of results obtained from machine learning models and\n",
    "statistical analyses.\\n\n",
    "iii.Overfitting in machine learning,What is overfitting, why it occurs, and how it can be addressed or prevented?\n",
    "-Overfitting occurs in machine learning when a model learns the training data too well, capturing\n",
    "noise and irrelevant patterns that do not generalize to new, unseen data. This results in poor\n",
    "performance on new data. Overfitting is often caused by excessively complex models.\n",
    "Techniques to address overfitting include using simpler models, feature selection, and\n",
    "regularization methods. Cross-validation is also employed to assess a model's performance on\n",
    "different subsets of the data.\\n\n",
    "iv.The role of exploratory data analysis (EDA) in data science. What is EDA, its objectives, and\n",
    "some common techniques used in exploratory data analysis?\n",
    "-Exploratory Data Analysis (EDA) is a critical phase in the data science process that involves\n",
    "visually and statistically exploring data sets to understand their key characteristics and patterns.\n",
    "The objectives of EDA include identifying trends, outliers, and relationships within the data.\n",
    "Common techniques used in EDA include summary statistics, data visualization (such as\n",
    "histograms, scatter plots, and box plots), and correlation analysis. EDA provides valuable\n",
    "insights that guide subsequent modeling and analysis decisions.\\n\n",
    "v. Big data. Can you provide an overview of what big data is, its characteristics, and the\n",
    "challenges and opportunities it presents in the field of data science?\n",
    "-Big data refers to large and complex datasets that exceed the processing capabilities of\n",
    "traditional data management tools. It is characterized by the three Vs: volume, velocity, and\n",
    "variety. Volume represents the sheer size of the data, velocity is the speed at which data is\n",
    "generated and processed, and variety refers to the diversity of data types. Big data presents\n",
    "challenges in terms of storage, processing, and analysis. However, it also offers opportunities\n",
    "for gaining valuable insights, making informed decisions, and discovering patterns that may not\n",
    "be apparent in smaller datasets.\\n\n",
    "vi. What is the difference between supervised and unsupervised learning in machine learning?\n",
    "-Supervised learning involves training a model using labeled data, where the algorithm learns to\n",
    "map input data to known output. In unsupervised learning, the algorithm explores patterns and\n",
    "relationships in unlabeled data without explicit guidance on the output.\\n\n",
    "vii. the concept of cross-validation in the context of machine learning?\n",
    "-Cross-validation is a technique used to assess the performance of a machine learning model by\n",
    "dividing the dataset into multiple subsets. The model is trained on several subsets and validated\n",
    "on the remaining data, allowing for a more robust evaluation of its generalization ability.\\n\n",
    "viii. What is feature engineering, and why is it important in machine learning?\n",
    "-Feature engineering involves selecting, transforming, or creating new features from the existing\n",
    "data to improve a model's performance. It is crucial in machine learning as the quality of\n",
    "features directly impacts the model's ability to learn and make accurate predictions.\\n\n",
    "ix. How does the bias-variance tradeoff influence the performance of a machine learning model?\n",
    "-The bias-variance tradeoff refers to the balance between underfitting (high bias) and overfitting\n",
    "(high variance). A model with high bias may oversimplify the data, while a high-variance model\n",
    "may fit the training data too closely. Achieving an optimal tradeoff is essential for a model to\n",
    "generalize well to new, unseen data.\\n\n",
    "x. What are some common distance metrics used in clustering algorithms?\n",
    "-Distance metrics, such as Euclidean distance and Manhattan distance, measure the\n",
    "dissimilarity between data points in clustering algorithms. These metrics help algorithms\n",
    "determine the proximity of points and group similar items together.\\n\n",
    "xi. How does regularization contribute to preventing overfitting in machine learning models?\n",
    "-Regularization techniques, such as L1 and L2 regularization, add penalty terms to the model's\n",
    "cost function. This discourages overly complex models by penalizing large coefficients, helping\n",
    "to prevent overfitting and improving a model's ability to generalize to new data.\\n\n",
    "xii. What is the role of a confusion matrix in evaluating the performance of a classification model?\n",
    "-A confusion matrix is a table that summarizes the performance of a classification model by\n",
    "comparing predicted and actual class labels. It includes metrics like true positives, true\n",
    "negatives, false positives, and false negatives, providing insights into the model's accuracy and\n",
    "error types.\\n\n",
    "xiii. How does the term \"one-hot encoding\" relate to the preprocessing of categorical variables in\n",
    "machine learning?\n",
    "-One-hot encoding is a technique used to convert categorical variables into a binary matrix\n",
    "format. Each category is represented by a binary column, and the presence or absence of a\n",
    "category is indicated by a 1 or 0, respectively. This encoding allows machine learning algorithms\n",
    "to work with categorical data effectively.\\n\n",
    "xiv. What is the purpose of a ROC curve, and how is it used in evaluating the performance of a\n",
    "binary classification model?\n",
    "-Answer: A Receiver Operating Characteristic (ROC) curve visually represents the tradeoff\n",
    "between true positive rate and false positive rate for different threshold values in a binary\n",
    "classification model. It helps assess the model's discrimination ability, and the area under the\n",
    "ROC curve (AUC) quantifies the overall performance.\\n\n",
    "xv.How does the concept of feature scaling contribute to the training of machine learning models?\n",
    "-Feature scaling involves standardizing or normalizing input features to a consistent scale. This\n",
    "is crucial in machine learning, as it ensures that features with different scales do not unduly\n",
    "influence the model. Scaling aids in better convergence during training and prevents certain\n",
    "features from dominating others in the learning process.\\n\n",
    "xvi. The process of model evaluation and selection in machine learning. What are the key metrics\n",
    "used to assess the performance of a model, and how does the choice of evaluation metrics\n",
    "depend on the specific problem and the nature of the data?\n",
    "-Model evaluation and selection are critical steps in the machine learning pipeline, as they\n",
    "determine the effectiveness and reliability of a predictive model. The process involves assessing\n",
    "the model's performance using various metrics and choosing the most suitable model based on\n",
    "these evaluations.\n",
    "The first step in model evaluation is typically splitting the dataset into training and testing sets.\n",
    "The model is trained on the training set, and its performance is evaluated on the testing set to\n",
    "simulate how well it will generalize to new, unseen data.\\n\n",
    "xvii. Several key metrics are used for model evaluation, depending on the nature of the problem:\n",
    "-Accuracy: This is a fundamental metric that measures the ratio of correctly predicted instances\n",
    "to the total instances. While accuracy is straightforward, it may not be suitable for imbalanced\n",
    "datasets where one class dominates.\n",
    "Precision and Recall: Precision is the ratio of true positive predictions to the total predicted\n",
    "positives, emphasizing the accuracy of positive predictions. Recall, on the other hand, is the\n",
    "ratio of true positives to the total actual positives, focusing on the ability to capture all positive\n",
    "instances. Precision and recall are particularly important in scenarios where false positives or\n",
    "false negatives have different consequences.\n",
    "F1 Score: The F1 score is the harmonic mean of precision and recall, providing a balanced\n",
    "measure that considers both false positives and false negatives. It is particularly useful when\n",
    "there is an uneven class distribution.\n",
    "-Area Under the Receiver Operating Characteristic Curve (AUC-ROC): AUC-ROC evaluates the\n",
    "performance of binary classification models by measuring the area under the ROC curve. It\n",
    "provides a comprehensive view of the tradeoff between true positive rate and false positive rate\n",
    "at various thresholds.\n",
    "Mean Squared Error (MSE) or Mean Absolute Error (MAE): metrics such as MSE or MAE\n",
    "quantify the difference between predicted and actual values. MSE penalizes larger errors more\n",
    "heavily than MAE, making it sensitive to outliers.\n",
    "The choice of evaluation metrics depends on the specific goals of the project and the\n",
    "characteristics of the data. For instance, in a fraud detection problem, precision might be\n",
    "prioritized to minimize false positives, even if it results in lower recall. In a medical diagnosis\n",
    "scenario, a balance between precision and recall might be essential to avoid both false positives\n",
    "and false negatives.\n",
    "Moreover, it's crucial to consider the business or domain-specific implications of model\n",
    "performance. In some cases, the cost of false positives and false negatives may differ\n",
    "significantly, influencing the choice of evaluation metrics. Therefore, a thoughtful analysis of the\n",
    "problem context and careful consideration of metric trade-offs are essential aspects of effective\n",
    "model evaluation and selection in data science.\n",
    "Illustrate the concept of ensemble learning in machine learning, detailing the principles behind\n",
    "ensemble methods and their applications. How do techniques like bagging, boosting, and\n",
    "stacking contribute to improving model performance, and under what circumstances would one\n",
    "ensemble method be preferred over another?\n",
    "Ensemble learning is a powerful paradigm in machine learning that involves combining the\n",
    "predictions of multiple models to enhance overall performance. The underlying principle is\n",
    "rooted in the idea that aggregating diverse models can mitigate individual model weaknesses,\n",
    "leading to a more robust and accurate predictive system.\n",
    "Bagging (Bootstrap Aggregating): Bagging involves training multiple instances of the same base\n",
    "model on different subsets of the training data, obtained through bootstrapping (sampling with\n",
    "replacement). The final prediction is often an average or a voting mechanism across these\n",
    "individual models. Popular bagging algorithms include Random Forests, which use decision\n",
    "trees as base learners. Bagging helps reduce overfitting and increases stability by leveraging\n",
    "the diversity introduced through bootstrap sampling.\n",
    "Boosting: Boosting focuses on sequentially training multiple weak learners, each attempting to\n",
    "correct the errors of its predecessor. Examples of boosting algorithms include AdaBoost,\n",
    "Gradient Boosting, and XGBoost. Boosting assigns different weights to instances based on their\n",
    "prediction errors, emphasizing difficult-to-classify instances. This iterative process leads to the\n",
    "creation of a strong learner capable of capturing complex patterns in the data.\n",
    "Stacking (Stacked Generalization): Stacking involves training multiple diverse models and\n",
    "combining their predictions through a meta-model. The meta-model learns to weigh the outputs\n",
    "of the base models, effectively leveraging their collective strengths. Stacking can be more\n",
    "sophisticated than other ensemble methods, as it allows for a hierarchical combination of\n",
    "models, potentially incorporating different types of algorithms in various layers.\n",
    "The choice between bagging, boosting, or stacking depends on the characteristics of the data\n",
    "and the goals of the modeling task:\n",
    "Bagging is often preferred when the base model is prone to high variance, such as in the case\n",
    "of decision trees. It helps in stabilizing the predictions and reducing overfitting.\n",
    "Boosting is effective when the base models are weak learners, and there is a need to improve\n",
    "overall predictive accuracy. It pays more attention to misclassified instances, making it suitable\n",
    "for handling imbalanced datasets.\n",
    "Stacking is advantageous when a diverse set of models with complementary strengths is\n",
    "available. Stacking can capture intricate patterns and relationships in the data by combining the\n",
    "unique perspectives of different models.\n",
    "In practice, the choice of ensemble method depends on factors like the nature of the data,\n",
    "computational resources, and the interpretability of the final model. Ensemble learning, by\n",
    "harnessing the collective intelligence of multiple models, stands as a versatile approach in\n",
    "improving the robustness and performance of machine learning systems across various\n",
    "domains and problem types.\n",
    "\n",
    "Below are the example questions and answer that you need to adhere, but you should be abled to answer to the \n",
    "all questions which is asking regarding the above mentioned areas.\n",
    "\n",
    "Q: What is the purpose of feature scaling in machine learning?\n",
    "Answer: Feature scaling ensures that input features are\n",
    "on a consistent scale, preventing certain\n",
    "features from dominating the learning\n",
    "process. Common techniques include\n",
    "Min-Max scaling and Z-score normalization.\n",
    "\n",
    "Q: Explain the concept of dimensionality reduction and its significance in data science.\n",
    "Answer: Dimensionality reduction involves reducing the\n",
    "number of input features while preserving\n",
    "essential information. Techniques like Principal\n",
    "Component Analysis (PCA) help mitigate the\n",
    "curse of dimensionality, improve model\n",
    "efficiency, and reveal underlying patterns.\n",
    "\n",
    "Q:  How does k-fold cross-validation work, and why is it used in machine learning?\n",
    "Answer: K-fold cross-validation involves partitioning\n",
    "the dataset into k subsets, training the model\n",
    "on k-1 folds, and testing on the remaining fold.\n",
    "This process is repeated k times, and the\n",
    "average performance is used for model\n",
    "evaluation. It provides a robust assessment of\n",
    "a model's generalization ability.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Response]\n",
      "The bias-variance tradeoff is a fundamental concept in machine learning that refers to the\n",
      "balance between underfitting (high bias) and overfitting (high variance). A model with high\n",
      "bias may oversimplify the data, while a high-variance model may fit the training data too\n",
      "closely. Achieving an optimal tradeoff is essential for a model to generalize well to new, unseen\n",
      "data.\n",
      "\n",
      "Bias is the difference between the expected value of a model's predictions and the true value of\n",
      "the target variable. A model with high bias will tend to make systematic errors, such as\n",
      "underestimating or overestimating the target variable\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"Can you explain the concept of\n",
    "bias-variance tradeoff and its\n",
    "impact on model performance?\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Answer the question given in the contex below:\n",
    "Context: {context}?\\n\n",
    "Question: {question} \\n\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "#print(\"[Prompt]\")\n",
    "#print(prompt)\n",
    "\n",
    "print(\"[Response]\")\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt,\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Response]\n",
      "The key considerations in selecting an appropriate machine learning algorithm for a given task include:\n",
      "\n",
      "* The type of data available\n",
      "* The size of the data\n",
      "* The desired level of accuracy\n",
      "* The computational resources available\n",
      "* The interpretability of the model\n",
      "\n",
      "Once these factors have been considered, the next step is to evaluate different algorithms to find the one that best meets the specific needs of the project.\n",
      "\n",
      "Here are some additional tips for selecting an appropriate machine learning algorithm:\n",
      "\n",
      "* Start with a simple algorithm and then experiment with more complex algorithms if necessary.\n",
      "* Use a validation set to evaluate the performance of different\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\" What are the key\n",
    "considerations in selecting an\n",
    "appropriate machine learning\n",
    "algorithm for a given task?\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Answer the question given in the contex below:\n",
    "Context: {context}?\\n\n",
    "Question: {question} \\n\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "#print(\"[Prompt]\")\n",
    "#print(prompt)\n",
    "\n",
    "print(\"[Response]\")\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt,\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Response]\n",
      "The key considerations in selecting an appropriate machine learning algorithm for a given task include:\n",
      "\n",
      "* The type of data available.\n",
      "* The desired level of accuracy.\n",
      "* The computational resources available.\n",
      "* The interpretability of the model.\n",
      "* The time constraints.\n",
      "\n",
      "Once these factors have been considered, the next step is to evaluate different algorithms to find the one that best meets the project's requirements. This can be done using a variety of techniques, such as cross-validation and grid search.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\" What are the key\n",
    "considerations in selecting an\n",
    "appropriate machine learning\n",
    "algorithm for a given task?\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Answer the question given in the contex below:\n",
    "Context: {context}?\\n\n",
    "Question: {question} \\n\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "#print(\"[Prompt]\")\n",
    "#print(prompt)\n",
    "\n",
    "print(\"[Response]\")\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt,\n",
    "        **parameters\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
